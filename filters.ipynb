{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "test_images_paths = glob('/home/andrej/git/CarND-P4-Advanced-Lane-Finding/test_images/*.jpg')\n",
    "\n",
    "image = cv2.imread('/home/andrej/git/CarND-P4-Advanced-Lane-Finding/test_images/straight_lines2.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp: [[ -4.86204634e-01  -1.49507925e+00   9.38982700e+02]\n [ -5.88418203e-15  -1.94426603e+00   8.74919714e+02]\n [ -8.89045781e-18  -2.37922580e-03   1.00000000e+00]]\nUnwarp: [[  1.45312500e-01  -7.81724211e-01   5.47500000e+02]\n [ -3.55271368e-15  -5.14332907e-01   4.50000000e+02]\n [ -8.23993651e-18  -1.22371412e-03   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "camera_matrix = [[1.15777930e+03, 0.00000000e+00, 6.67111054e+02],\n",
    " [0.00000000e+00, 1.15282291e+03, 3.86128937e+02],\n",
    " [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]\n",
    "\n",
    "dist_coeffs = [[-0.24688775, -0.02373134, -0.00109842, 0.00035108, -0.00258569]]\n",
    "\n",
    "# Warping perspective\n",
    "def perspective_warp():\n",
    "    width = 1280\n",
    "    height = 720\n",
    "    top_left =[594, 450] # [520, 500] # [7/16*width, 6/10*height]\n",
    "    top_right = [687, 450]#[768, 500] # [9/16*width, 6/10*height]\n",
    "    bottom_left = [262, 670] # [1/16*width, 9/10*height]\n",
    "    bottom_right = [1044, 670] #[15/16*width, 9/10*height]\n",
    "    src_points = np.float32([top_left, top_right, bottom_left, bottom_right])\n",
    "    dst_points = np.float32([\n",
    "        [4/16*width, 0/10*height], # top left\n",
    "        [12/16*width, 0/10*height], # top right\n",
    "        [4/16*width, 10/10*height], # bottom left\n",
    "        [12/16*width, 10/10*height]  # bottom right\n",
    "    ])\n",
    "    warp_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    unwarp_matrix = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "    return warp_matrix, unwarp_matrix\n",
    "\n",
    "\n",
    "def warp_image(image, warp_matrix):\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    warped_image = cv2.warpPerspective(image, warp_matrix, (width, height))\n",
    "    return warped_image\n",
    "\n",
    "#######################################################################\n",
    "warp_matrix, unwarp_matrix = perspective_warp()\n",
    "print ('Warp:',warp_matrix)\n",
    "print('Unwarp:', unwarp_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\nLeft points (top/bottom): (320, 0) (320, 720)\nRight points (top/bottom): (960, 0) (960, 720)\nLane width: 640 px\n"
     ]
    }
   ],
   "source": [
    "def showImage(image, title='Photo'):\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def showGrayImage(image, title='Photo'):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def showChannels(image):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "\n",
    "    for c, ax in zip(range(3), axs):\n",
    "        tmp_img = np.zeros(image.shape, dtype=\"uint8\")\n",
    "        tmp_img[:,:,c] = image[:,:,c]\n",
    "        tmp_img = cv2.cvtColor(tmp_img, cv2.COLOR_RGB2GRAY)\n",
    "        ax.imshow(tmp_img, cmap='gray')\n",
    "        ax.set_axis_off()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "X_images = []\n",
    "\n",
    "for image_path in test_images_paths:\n",
    "    image = plt.imread(image_path)\n",
    "    #print(image.shape)\n",
    "    X_images.append(image)\n",
    "    \n",
    "X_images = np.array(X_images)\n",
    "#print(X_images.shape)\n",
    "\n",
    "top_left =(594, 450) # [520, 500] # [7/16*width, 6/10*height]\n",
    "top_right = (687, 450)#[768, 500] # [9/16*width, 6/10*height]\n",
    "bottom_left = (262, 670) # [1/16*width, 9/10*height]\n",
    "bottom_right = (1044, 670) #[15/16*width, 9/10*height]\n",
    "\n",
    "width = X_images[0].shape[1]\n",
    "print(width)\n",
    "height = X_images[0].shape[0]\n",
    "top_left_warped = (int(4/16*width), int(0/10*height)) # top left\n",
    "top_right_warped = (int(12/16*width), int(0/10*height)) # top right\n",
    "bottom_left_warped = (int(4/16*width), int(10/10*height))# bottom left\n",
    "bottom_right_warped = (int(12/16*width), int(10/10*height))# bottom right\n",
    "\n",
    "print('Left points (top/bottom):', top_left_warped, bottom_left_warped)\n",
    "print('Right points (top/bottom):', top_right_warped, bottom_right_warped)\n",
    "print('Lane width:', abs(bottom_left_warped[0] - bottom_right_warped[0]), 'px')\n",
    "\n",
    "lines_image = np.copy(X_images[1])\n",
    "warped_image = np.copy(warp_image(lines_image, warp_matrix))\n",
    "\n",
    "lines_image = cv2.line(lines_image, top_left, bottom_left, (255,0,0), 3)\n",
    "lines_image = cv2.line(lines_image, top_right, bottom_right, (255,0,0), 3)\n",
    "warped_image = cv2.line(warped_image, top_left_warped, bottom_left_warped, (255,0,0), 3)\n",
    "warped_image = cv2.line(warped_image, top_right_warped, bottom_right_warped, (255,0,0), 3)\n",
    "\n",
    "showImage(lines_image, 'Lines drawn')\n",
    "showImage(warped_image, 'Warped image')\n",
    "\n",
    "unwarp_again_ffs = warp_image(warped_image, unwarp_matrix)\n",
    "showImage(unwarp_again_ffs, 'Unwarped again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White lane lines extraction\n",
    "def white_lines_RGB(image):\n",
    "    color_select_img = np.copy(image)\n",
    "    red_threshold = 200\n",
    "    green_threshold = 185\n",
    "    blue_threshold = 199\n",
    "\n",
    "    # Identify pixels below the threshold. Black 'em out\n",
    "    colour_thresholds = (image[:,:,0] < red_threshold) | \\\n",
    "                 (image[:,:,1] < green_threshold) | \\\n",
    "                 (image[:,:,2] < blue_threshold)\n",
    "    color_select_img[colour_thresholds] = [0,0,0]\n",
    "    color_select_img = cv2.cvtColor(color_select_img, cv2.COLOR_RGB2GRAY)\n",
    "    slice = color_select_img[:,:] > 0\n",
    "    color_select_img[slice] = 255\n",
    "    return color_select_img\n",
    "\n",
    "\n",
    "# Yellow lane lines extraction\n",
    "def yellow_lines_RGB(image):\n",
    "    color_select_img = np.copy(image)\n",
    "    red_threshold = 220\n",
    "    green_threshold = 180\n",
    "    blue_threshold = 40\n",
    "    #rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "    # Identify pixels below the threshold. Black 'em out\n",
    "    colour_thresholds = (image[:,:,0] < red_threshold) | \\\n",
    "                 (image[:,:,1] < green_threshold) | \\\n",
    "                 (image[:,:,2] < blue_threshold)\n",
    "    color_select_img[colour_thresholds] = [0,0,0]\n",
    "    color_select_img = cv2.cvtColor(color_select_img, cv2.COLOR_RGB2GRAY)\n",
    "    slice = color_select_img[:,:] > 0\n",
    "    color_select_img[slice] = 255\n",
    "    return color_select_img\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#for img in test_images:\n",
    "#    showChannels(cv2.cvtColor(plt.imread(img), cv2.COLOR_RGB2HLS))\n",
    "    \n",
    "#print('RGB mode:')\n",
    "#for img in test_images:\n",
    "#    showChannels(plt.imread(img))\n",
    "\n",
    "for img in X_images:\n",
    "    image = yellow_lines_RGB(img)\n",
    "    showGrayImage(image, 'Yellows and whites in RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sobel(gray, direction):\n",
    "    if direction == 'x': # Sobel X\n",
    "        return cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        return cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "\n",
    "\n",
    "# From the Udacity Advanced Lane Finding lectures\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude\n",
    "    # is > thresh_min and < thresh_max\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sobel_binary\n",
    "\n",
    "\n",
    "# Define a function that applies Sobel x and y,\n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_threshold(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    magnitude_sobel = np.sqrt((sobelx * sobelx + sobely * sobely))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * magnitude_sobel / np.max(magnitude_sobel))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sobel_binary\n",
    "\n",
    "\n",
    "# Define a function that applies Sobel x and y,\n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi / 2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    sobel_binary = np.zeros_like(direction_grad)\n",
    "    sobel_binary[(direction_grad >= thresh[0]) & (direction_grad <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sobel_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color and gradient thresholds \n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    S = hls[:,:,2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary\n",
    "\n",
    "def sobel_select(img, thresh=(20, 100)):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_new = img[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(img_new, cv2.CV_64F, 1, 0)  # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx)  # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    sobel_x_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_x_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return sobel_x_binary\n",
    "\n",
    "\n",
    "def find_laneLines_sobel(img, ksize=3, thresh=(0,255), mag_thresh=(0,255), dir_thresh=(0, np.pi/2)):\n",
    "    # Choose a larger k-size (odd number) to get smoother gradient measurements\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=thresh)\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=thresh)\n",
    "    mag_binary = mag_threshold(img, sobel_kernel=ksize, mag_thresh=mag_thresh)\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=dir_thresh)\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "for ind in np.arange(0, len(X_images)):\n",
    "    test_img = np.copy(X_images[ind])\n",
    "    test_img = cv2.undistort(test_img, np.array(camera_matrix), np.array(dist_coeffs), None, np.array(camera_matrix))\n",
    "    #plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/undistorted_' + test_images_paths[ind].split('/')[-1],\n",
    "    #           arr=test_img, format='jpg')\n",
    "    test_img = warp_image(test_img, warp_matrix)\n",
    "    showImage(test_img, 'Test image')\n",
    "    plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/warped_' + test_images_paths[ind].split('/')[-1],\n",
    "               arr=test_img, format='jpg')\n",
    "    test_img = cv2.blur(test_img, (9,9))\n",
    "    \n",
    "    final = cv2.add(find_laneLines_sobel(\n",
    "            test_img, ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.8, 1.)\n",
    "            ),\n",
    "        find_laneLines_sobel(\n",
    "            test_img, ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.01, 0.2)\n",
    "            )\n",
    "    )\n",
    "    final[final>0] = 255\n",
    "    #final[:,final.shape[1]-100:final.shape[1]] = 0\n",
    "    #final[:,:200] = 0\n",
    "    #final[500:final.shape[0], 450:900] = 0\n",
    "    showGrayImage(\n",
    "        final, \n",
    "        'Lane lines - combined sobel'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for image processing\n",
    "def pipeline(image):\n",
    "    image = cv2.undistort(image, np.array(camera_matrix), np.array(dist_coeffs), None, np.array(camera_matrix))\n",
    "    image = warp_image(image, warp_matrix)\n",
    "    \n",
    "    color_mask = cv2.add(yellow_lines_RGB(image), white_lines_RGB(image))\n",
    "    color_mask[color_mask>0] = 255\n",
    "    \n",
    "    sobel_mask = cv2.add(\n",
    "        find_laneLines_sobel(\n",
    "            cv2.blur(image, (9,9)), ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.8, 1.)\n",
    "            ),\n",
    "        find_laneLines_sobel(\n",
    "            cv2.blur(image, (9,9)), ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.01, 0.2)\n",
    "            )\n",
    "    )\n",
    "    sobel_mask[sobel_mask>0] = 255\n",
    "    # Eliminate noise\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    sobel_mask = cv2.erode(sobel_mask,kernel,iterations = 1)\n",
    "    sobel_mask = cv2.morphologyEx(sobel_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    hls_mask = hls_select(cv2.blur(image, (9,9)), thresh=(115, 255))\n",
    "    hls_mask[hls_mask>0] = 255\n",
    "    return np.dstack((color_mask, hls_mask, sobel_mask))*255\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# Testing the pipeline\n",
    "for ind in np.arange(0, len(test_images_paths)):\n",
    "    result = pipeline(X_images[ind])\n",
    "    showImage(result, 'Processed image')\n",
    "    #plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/lane_lines_mask_' + test_images_paths[ind].split('/')[-1],\n",
    "    #           arr=result, format='jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  3.85431939e-05  -1.70072473e-02   3.32913402e+02]\nright line: [ -3.57497294e-05  -8.64126824e-03   9.70527354e+02]\ndiff: [  7.42929233e-05  -8.36597910e-03  -6.37613952e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3895.79935167 m 4200.47334253 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [ -6.31198900e-05   6.86610744e-02   3.19869705e+02]\nright line: [ -8.90959950e-05   6.58421070e-02   9.36025510e+02]\ndiff: [  2.59761050e-05   2.81896735e-03  -6.16155804e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378.84237294 m 1685.45137843 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  5.74052494e-04  -7.10868343e-01   5.27420943e+02]\nright line: [ -8.91017783e-06   4.32285040e-02   9.60411999e+02]\ndiff: [  5.82962672e-04  -7.54096847e-01  -4.32991056e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.660943789 m 16851.9825606 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.26900214e-04  -4.97181776e-01   6.07121714e+02]\nright line: [  1.68635342e-04  -4.05606827e-01   1.19801318e+03]\ndiff: [  5.82648722e-05  -9.15749488e-02  -5.90891467e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662.303499775 m 891.067787516 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.60320838e-04  -5.07806552e-01   5.87604071e+02]\nright line: [  2.78712163e-04  -5.10847693e-01   1.19504682e+03]\ndiff: [ -1.83913246e-05   3.04114084e-03  -6.07442746e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577.08554384 m 538.916828356 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  9.71583434e-05  -1.74418838e-01   4.45154597e+02]\nright line: [  2.31768707e-04  -4.19523755e-01   1.17182868e+03]\ndiff: [ -1.34610364e-04   2.45104917e-01  -7.26674080e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545.47069646 m 647.983937934 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [ -3.62987371e-04   5.46427982e-01   1.86193969e+02]\nright line: [ -4.02085798e-04   5.76093723e-01   7.95795681e+02]\ndiff: [  3.90984274e-05  -2.96657416e-02  -6.09601712e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413.658311073 m 373.428184053 m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.66679088e-05  -1.38457394e-01   4.33930455e+02]\nright line: [  6.15243398e-04  -6.70749758e-01   1.20053804e+03]\ndiff: [ -5.88575489e-04   5.32292364e-01  -7.66607582e+02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5631.99790126 m 244.37272765 m\n"
     ]
    }
   ],
   "source": [
    "# Find the lines\n",
    "def mask(image):\n",
    "    image = cv2.undistort(image, np.array(camera_matrix), np.array(dist_coeffs), None, np.array(camera_matrix))\n",
    "    image = warp_image(image, warp_matrix)\n",
    "    color_mask = cv2.add(yellow_lines_RGB(image), white_lines_RGB(image))\n",
    "    color_mask[color_mask > 0] = 255\n",
    "    #color_mask = np.array(color_mask, dtype=np.int8)\n",
    "    #showGrayImage(color_mask, 'Color mask')\n",
    "    sobel_mask = cv2.add(\n",
    "        find_laneLines_sobel(\n",
    "            cv2.blur(image, (9,9)), ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.8, 1.)\n",
    "            ),\n",
    "        find_laneLines_sobel(\n",
    "            cv2.blur(image, (9,9)), ksize=3, \n",
    "            thresh=(15, 90), \n",
    "            mag_thresh=(10, 90), \n",
    "            dir_thresh=(0.01, 0.2)\n",
    "            )\n",
    "    )\n",
    "    sobel_mask[sobel_mask>0] = 255\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    sobel_mask = cv2.erode(sobel_mask,kernel,iterations = 1)\n",
    "    sobel_mask = cv2.morphologyEx(sobel_mask, cv2.MORPH_OPEN, kernel)\n",
    "    #sobel_mask = np.array(sobel_mask, dtype=np.int8)\n",
    "    #showGrayImage(sobel_mask, 'Sobel mask')\n",
    "    hls_mask = hls_select(cv2.blur(image, (9,9)), thresh=(115, 255))\n",
    "    hls_mask[hls_mask>0] = 255\n",
    "    #hls_mask = np.array(hls_mask, dtype=np.int8)\n",
    "    #showGrayImage(hls_mask, 'HLS_mask')\n",
    "    result_mask = np.zeros_like(hls_mask)\n",
    "    result_mask[sobel_mask > 0] = 255\n",
    "    result_mask[hls_mask > 0] = 255\n",
    "    result_mask[color_mask > 0] = 255\n",
    "    result_mask[:,result_mask.shape[1]-100:result_mask.shape[1]] = 0\n",
    "    result_mask[:,:200] = 0\n",
    "    result_mask[500:result_mask.shape[0], 450:900] = 0\n",
    "    return result_mask\n",
    "\n",
    "\n",
    "def line_detect(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[np.int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 100\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    print('left line:', left_fit)\n",
    "    print('right line:', right_fit)\n",
    "    print('diff:', left_fit-right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "    #plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/lane_detection_' + test_images_paths[ind].split('/')[-1],\n",
    "    #           arr=out_img, format='jpg')\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30./720. # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/640. # meters per pixel in x dimension\n",
    "    \n",
    "    # See if the curvatures align now!\n",
    "    # Udacity code here, adapted to fit the project's needs\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "#######################################################################\n",
    "# Testing the pipeline\n",
    "X_masks = []\n",
    "for ind in np.arange(0, len(test_images_paths)):\n",
    "    result_mask = mask(X_images[ind])\n",
    "    X_masks.append(result_mask)\n",
    "    line_detect(result_mask)\n",
    "    \n",
    "X_masks = np.array(X_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using convolutions\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(image[int(3*image.shape[0]/8):,:int(image.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(image[int(3*image.shape[0]/8):,int(image.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(image.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,image.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "# Read in a thresholded image\n",
    "for ind in range(len(X_masks)):\n",
    "    warped = np.copy(X_masks[ind])\n",
    "    window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "    \n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "    \n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "    \n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "    \n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage= np.dstack((warped, warped, warped))*255 # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "     \n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "    \n",
    "    # Display the final results\n",
    "    warped = cv2.merge((warped, warped, warped))\n",
    "    output = cv2.addWeighted(output, 1.0, warped, 0.7, 0.0)\n",
    "    \n",
    "    plt.imshow(output)\n",
    "    plt.title('window fitting results')\n",
    "    plt.show()\n",
    "    #plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/lane_lines_convolved_' + test_images_paths[ind].split('/')[-1],\n",
    "    #           arr=output, format='jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  3.85431939e-05  -1.70072473e-02   3.32913402e+02]\nright line: [ -3.57497294e-05  -8.64126824e-03   9.70527354e+02]\ndiff: [  7.42929233e-05  -8.36597910e-03  -6.37613952e+02]\n3895.79935167 m 4200.47334253 m\n0.017343749999999998 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [ -6.31198900e-05   6.86610744e-02   3.19869705e+02]\nright line: [ -8.90959950e-05   6.58421070e-02   9.36025510e+02]\ndiff: [  2.59761050e-05   2.81896735e-03  -6.16155804e+02]\n2378.84237294 m 1685.45137843 m\n-0.023125 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  5.74052494e-04  -7.10868343e-01   5.27420943e+02]\nright line: [ -8.91017783e-06   4.32285040e-02   9.60411999e+02]\ndiff: [  5.82962672e-04  -7.54096847e-01  -4.32991056e+02]\n261.660943789 m 16851.9825606 m\n0.05203125 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.26900214e-04  -4.97181776e-01   6.07121714e+02]\nright line: [  1.68635342e-04  -4.05606827e-01   1.19801318e+03]\ndiff: [  5.82648722e-05  -9.15749488e-02  -5.90891467e+02]\n662.303499775 m 891.067787516 m\n0.23125 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.60320838e-04  -5.07806552e-01   5.87604071e+02]\nright line: [  2.78712163e-04  -5.10847693e-01   1.19504682e+03]\ndiff: [ -1.83913246e-05   3.04114084e-03  -6.07442746e+02]\n577.08554384 m 538.916828356 m\n0.13874999999999998 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  9.71583434e-05  -1.74418838e-01   4.45154597e+02]\nright line: [  2.31768707e-04  -4.19523755e-01   1.17182868e+03]\ndiff: [ -1.34610364e-04   2.45104917e-01  -7.26674080e+02]\n1545.47069646 m 647.983937934 m\n0.22546875 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [ -3.62987371e-04   5.46427982e-01   1.86193969e+02]\nright line: [ -4.02085798e-04   5.76093723e-01   7.95795681e+02]\ndiff: [  3.90984274e-05  -2.96657416e-02  -6.09601712e+02]\n413.658311073 m 373.428184053 m\n0.32375 m distance to the lane center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left line: [  2.66679088e-05  -1.38457394e-01   4.33930455e+02]\nright line: [  6.15243398e-04  -6.70749758e-01   1.20053804e+03]\ndiff: [ -5.88575489e-04   5.32292364e-01  -7.66607582e+02]\n5631.99790126 m 244.37272765 m\n0.300625 m distance to the lane center\n"
     ]
    }
   ],
   "source": [
    "# Let's plot some stuff on top\n",
    "def line_detect_mod(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[np.int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 100\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    print('left line:', left_fit)\n",
    "    print('right line:', right_fit)\n",
    "    print('diff:', left_fit-right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    #plt.xlim(0, 1280)\n",
    "    #plt.ylim(720, 0)\n",
    "    #plt.show()\n",
    "    #plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/lane_detection_' + test_images_paths[ind].split('/')[-1],\n",
    "    #           arr=out_img, format='jpg')\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30./720. # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/640. # meters per pixel in x dimension\n",
    "    \n",
    "    # See if the curvatures align now!\n",
    "    # Udacity code here, adapted to fit the project's needs\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    print(left_curverad, 'm', right_curverad, 'm')\n",
    "    \n",
    "    left_line_bottom = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]\n",
    "    right_line_bottom = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]\n",
    "    \n",
    "    image_center = 1280/2\n",
    "    lane_center = int((right_line_bottom - left_line_bottom) / 2. + left_line_bottom)\n",
    "    dist_center = lane_center - image_center\n",
    "    \n",
    "    dist_center *= xm_per_pix\n",
    "    print(dist_center, 'm distance to the lane center')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    #pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    #pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    #pts = np.hstack((pts_left, pts_right))\n",
    "    #cv2.fillPoly(out_img, np.int_(pts), (255,255,0))\n",
    "    return left_fit, right_fit, ploty, left_fitx, right_fitx, left_curverad, dist_center\n",
    "\n",
    "\n",
    "def frameOverlay(frame, left_fitx_p, right_fitx_p, ploty, left_curvature, distance, width=1280, height=720, color=(0, 255, 0)):\n",
    "    # Create an image to draw the lines on\n",
    "    #warp_zero = np.zeros((width, height), dtype=np.uint8)\n",
    "    warp_zero = np.zeros_like(frame[:,:,1]).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    color_warp = cv2.merge((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx_p, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx_p, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), color)\n",
    "    #cv2.line(color_warp, top_right_warped, bottom_right_warped, (255,0,0), 5)\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, unwarp_matrix, (width, height))\n",
    "    #plt.imshow(newwarp)\n",
    "    #plt.show()\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(frame, 1, newwarp, 0.3, 0)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    cv2.putText(result, 'Left lane radius: ' + str(left_curvature) + 'm', (30, 50), font, 1.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, 'Distance to lane center: ' + str(distance*100) + 'cm', (30, 80), font, 1.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "    return result\n",
    "\n",
    "\n",
    "for image in X_images:\n",
    "    #image_warped = warp_image(image, warp_matrix)\n",
    "    #plt.imshow(image_warped)\n",
    "    #plt.show()\n",
    "    #image_unwarped = warp_image(image_warped, unwarp_matrix)\n",
    "    #plt.imshow(image_unwarped)\n",
    "    #plt.show()\n",
    "    image_mask = mask(image)\n",
    "    #plt.imshow(image_mask, cmap='gray')\n",
    "    #plt.show()\n",
    "    \n",
    "    left_line, right_line, ploty, left_fitx, right_fitx, left_crad, dist_center = line_detect_mod(image_mask)\n",
    "    #print(left_line, right_line, ploty, left_fitx, right_fitx)\n",
    "    image_overlay = frameOverlay(image, left_fitx, right_fitx, ploty, left_crad, dist_center, image.shape[1], image.shape[0], (0, 255, 0))\n",
    "    plt.imshow(image_overlay)\n",
    "    plt.title(\"Image (overlaid)\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_example = plt.imread('./camera_cal/calibration1.jpg')\n",
    "calibrated_example = cv2.undistort(calib_example, np.array(camera_matrix), np.array(dist_coeffs), None, np.array(camera_matrix))\n",
    "\n",
    "plt.imsave(fname='/home/andrej/git/CarND-P4-Advanced-Lane-Finding/examples/undistorted_calibration1.jpg',\n",
    "           arr=calibrated_example, format='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
